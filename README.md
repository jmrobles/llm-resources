# llm-resources
LLM and transformers resources


## Essential Papers

- [All you need is attention](https://arxiv.org/pdf/1706.03762): Origen of Transformers
- [Self-Instruct: Aligning Language Model with Self Generated Instructions](https://arxiv.org/pdf/2212.10560): Origin of ChatGPT like based Instruction LLM

## Open-source Data Initiatives

- [Open Assistant](https://open-assistant.io/): Open source dataset for training LLM

## Instruction-following models
- [Standford Alpaca](https://github.com/tatsu-lab/stanford_alpaca): An Instruction-following model for LLaMA Model

## LLM in domestic GPUs/CPUs

- [RWKV-LM](https://github.com/BlinkDL/RWKV-LM)
- [Alpaca LoRA 4-bit](https://github.com/johnsmith0031/alpaca_lora_4bit)
- [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp)
- [FlexGen](https://github.com/FMInference/FlexGen): FlexGen is a high-throughput generation engine for running large language models with limited GPU memory.

## Frameworks
- [Autodoc](https://github.com/context-labs/autodoc): Auto generate documentation from your repository.
- [Prompt Engine](https://github.com/microsoft/prompt-engine) microsoft/prompt-engine: A library for helping developers craft prompts for Large Language Models.
- [Baize](https://github.com/project-baize/baize-chatbot): Baize is an open-source chat model trained with LoRA.
- [Nebullvm](https://github.com/nebuly-ai/nebullvm): Plug and play modules to optimize the performances of your AI systems (ChatGPT like systems).
- [LMFlow](https://github.com/OptimalScale/LMFlow): An extensible, convenient, and efficient toolbox for finetuning large machine learning models.
- [Text Generation Inference](https://github.com/huggingface/text-generation-inference): A Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets.

## Multi-GPU

- [GPT-NeoX](https://github.com/EleutherAI/gpt-neox): EleutherAI's library for training large-scale language models on GPUs. 
## Benchmarks

- [HumanEval](https://github.com/openai/human-eval): Hand-written evaluation set
